# slurm.conf file generated by configurator easy.html.
# Put this file on all nodes of your cluster.
# See the slurm.conf man page for more information.
#
ClusterName=cluster
SlurmctldHost={{ controller }}
#
#MailProg=/bin/mail
#MpiDefault=
#MpiParams=ports=#-#
ProctrackType=proctrack/cgroup
ReturnToService=1
SlurmctldPidFile=/opt/pkb/slurmctld.pid
#SlurmctldPort=6817
SlurmdPidFile=/opt/pkb/slurmd.pid
#SlurmdPort=6818
SlurmdSpoolDir=/opt/pkb/slurmd
SlurmUser={{ user }}
#SlurmdUser=root
StateSaveLocation=/opt/pkb/slurmctld
#SwitchType=
TaskPlugin=task/affinity,task/cgroup
#
#
# TIMERS
#KillWait=30
#MinJobAge=300
#SlurmctldTimeout=120
#SlurmdTimeout=300
#
#
# SCHEDULING
SchedulerType=sched/backfill
SelectType=select/cons_tres
SelectTypeParameters=CR_CORE
#
#
# LOGGING AND ACCOUNTING
#AccountingStorageType=
#JobAcctGatherFrequency=30
#JobAcctGatherType=
#SlurmctldDebug=info
SlurmctldLogFile=/opt/pkb/slurmctld.log
SlurmdDebug=debug
SlurmdLogFile=/opt/pkb/slurmd.log
#
#
# COMPUTE NODES
NodeName={{ controller }} CPUs={{ cpus }} Sockets={{ sockets }} CoresPerSocket={{ cores_per_socket }} ThreadsPerCore={{ threads_per_core }} State=UNKNOWN Weight=1
{% if workers | length > 0 %}
NodeName={{ workers }} CPUs={{ cpus }} Sockets={{ sockets }} CoresPerSocket={{ cores_per_socket }} ThreadsPerCore={{ threads_per_core }} State=UNKNOWN Weight=10
{% endif %}
PartitionName=pkb Nodes=ALL Default=YES MaxTime=INFINITE State=UP
